{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "import autokeras as ak\n",
    "import kerastuner as kt\n",
    "import tensorflow as tf\n",
    "\n",
    "models        = []\n",
    "strategyArray = []\n",
    "gainArray     = []\n",
    "lossArray     = []\n",
    "ampNumber     = 4\n",
    "\n",
    "originalDataSet = pd.read_csv('dataset.txt', sep = ',',header = None)\n",
    "originalDataSet = originalDataSet.sample(frac = 1, random_state = 5)\n",
    "\n",
    "binaryDataSet   = []\n",
    "\n",
    "for line in originalDataSet.values:\n",
    "    myList = [1 if i != 0 else 0 for i in line[:40]]\n",
    "    myList.extend(line[40:])\n",
    "    binaryDataSet.append(myList)\n",
    "\n",
    "binaryDataSet = pd.DataFrame(binaryDataSet)\n",
    "gainScaler    = MinMaxScaler(feature_range = (-1, 1))\n",
    "lossScaler    = MinMaxScaler(feature_range = (-1, 1))\n",
    "\n",
    "gainScalerAux = []\n",
    "lossScalerAux = []\n",
    "\n",
    "for i in range(0, ampNumber * 2, 2):\n",
    "    gainScalerAux.extend(binaryDataSet.values[:, 40 + i])\n",
    "    lossScalerAux.extend(binaryDataSet.values[:, 40 + i + 1])\n",
    "\n",
    "gainScaler.fit(np.array(gainScalerAux).reshape(-1, 1))\n",
    "lossScaler.fit(np.array(lossScalerAux).reshape(-1, 1))\n",
    "\n",
    "def loadDataset(): \n",
    "    dataSet = binaryDataSet.values[:, :40]\n",
    "    \n",
    "    for i in range(0, ampNumber * 2, 2):\n",
    "        gain    = np.array(binaryDataSet.values[:, 40 + i])\n",
    "        gain    = gainScaler.transform(gain.reshape(-1, 1))\n",
    "        dataSet = np.hstack((dataSet, gain))\n",
    "        \n",
    "        loss    = np.array(binaryDataSet.values[:, 40 + i + 1])\n",
    "        loss    = lossScaler.transform(loss.reshape(-1, 1))\n",
    "        dataSet = np.hstack((dataSet, loss))\n",
    "            \n",
    "    X, y = np.array(dataSet[:, :40]), np.array(dataSet[:, 40:])\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def invertGainNorm(value):\n",
    "    auxArray = np.array([value, 0, 0, 0, 0, 0]).reshape(-1, 1)\n",
    "    return round(gainScaler.inverse_transform(auxArray)[0][0])\n",
    "\n",
    "def invertLossNorm(value):\n",
    "    auxArray = np.array([value, 0, 0, 0, 0, 0]).reshape(-1, 1)\n",
    "    return round(lossScaler.inverse_transform(auxArray)[0][0])\n",
    "    \n",
    "def getGainError(value1, value2):\n",
    "    return (invertGainNorm(value1) - invertGainNorm(value2))**2\n",
    "\n",
    "def getLossError(value1, value2):\n",
    "    return (invertLossNorm(value1) - invertLossNorm(value2))**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initModels():\n",
    "    X, y  = loadDataset()\n",
    "    model = MultiOutputRegressor(KNeighborsRegressor())\n",
    "    \n",
    "    gsc = GridSearchCV(\n",
    "        estimator  = KNeighborsRegressor(),\n",
    "        param_grid = {\"n_neighbors\": [3, 4, 5, 6], #5\n",
    "                      \"weights\":     [\"uniform\", \"distance\"], #uniform\n",
    "                      \"algorithm\":   [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"], #auto\n",
    "                      \"leaf_size\":   [10, 20, 30, 40]}, #30\n",
    "        cv         = 5, \n",
    "        scoring    = 'neg_mean_squared_error', \n",
    "        verbose    = 0,\n",
    "        n_jobs     = -1)\n",
    "    \n",
    "    for i in range(0, ampNumber * 2, 2):\n",
    "        grid_result = MultiOutputRegressor(gsc).fit(X, y[:, i:i + 2])\n",
    "\n",
    "        print(grid_result.estimators_[0].best_params_)\n",
    "        print(grid_result.estimators_[1].best_params_)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossValidate(regressor, X, y, folds = 5):\n",
    "    foldSize   = math.ceil(X.shape[0] / folds)\n",
    "    gainErrors = []\n",
    "    lossErrors = []\n",
    "    \n",
    "    for i in range(folds): \n",
    "        sliceBegin = i * foldSize\n",
    "        sliceEnd   = (i + 1) * foldSize\n",
    "        \n",
    "        X_train = np.delete(X, np.s_[sliceBegin: sliceEnd], 0)\n",
    "        y_train = np.delete(y, np.s_[sliceBegin: sliceEnd], 0)\n",
    "        \n",
    "        regressor.fit(X_train, y_train, verbose = False)\n",
    "        X_test = X[sliceBegin: sliceEnd]\n",
    "        y_test = y[sliceBegin: sliceEnd]\n",
    "        \n",
    "        gainError = 0\n",
    "        lossError = 0\n",
    "        \n",
    "        prediction = regressor.predict(X_test)\n",
    "        \n",
    "        for predicted, expected in zip(prediction, y_test):\n",
    "            gainError += getGainError(predicted[0], expected[0]) \n",
    "            lossError += getLossError(predicted[1], expected[1])\n",
    "                 \n",
    "        gainErrors.append((gainError / ampNumber) / foldSize)\n",
    "        lossErrors.append((lossError / ampNumber) / foldSize) # average loss error by amp\n",
    "        \n",
    "    return np.array(gainErrors), np.array(lossErrors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def trainModel(models):   \n",
    "    X, y                   = loadDataset()\n",
    "    gainErrors, lossErrors = crossValidate(models[0], X, y[:, 0: 2])\n",
    "    print(gainErrors, \"=> %0.2f (+/- %0.2f)\" % (math.sqrt(np.mean(gainErrors)), gainErrors.std() * 2))\n",
    "    print(lossErrors, \"=> %0.2f (+/- %0.2f)\\n\" % (math.sqrt(np.mean(lossErrors)), lossErrors.std() * 2))\n",
    "    \n",
    "    gainArray.append(gainErrors)\n",
    "    lossArray.append(lossErrors)\n",
    "    strategyArray.append(\"ANN - Amp 1\")\n",
    "    \n",
    "    prediction = models[0].predict(X)\n",
    "    \n",
    "    for i in range(1, ampNumber):\n",
    "        #gainErrors, lossErrors = crossValidate(models[i], X, y[:, i * 2: i * 2 + 2]) \n",
    "        gainErrors, lossErrors = crossValidate(models[i], np.hstack((X, prediction)), y[:, i * 2: i * 2 + 2])  \n",
    "        print(gainErrors, \"=> %0.2f (+/- %0.2f)\" % (math.sqrt(np.mean(gainErrors)), gainErrors.std() * 2))\n",
    "        print(lossErrors, \"=> %0.2f (+/- %0.2f)\\n\" % (math.sqrt(np.mean(lossErrors)), lossErrors.std() * 2))\n",
    "\n",
    "        gainArray.append(gainErrors)\n",
    "        lossArray.append(lossErrors)\n",
    "        strategyArray.append(\"ANN - Amp {}\".format(i + 1))\n",
    "        \n",
    "        prediction = models[i].predict(np.hstack((X, prediction)))\n",
    "        #prediction = models[i].predict(X)\n",
    "    \n",
    "    return gainErrors, lossErrors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotDistribution(models):\n",
    "    train_results = []\n",
    "    test_results  = []\n",
    "    features, result                 = loadDataset()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, result, test_size = 0.3, random_state = 5)\n",
    "    \n",
    "    models[0].fit(X_train, y_train[:, 0: 2])\n",
    "    train_results.append(models[0].predict(X_train))\n",
    "    test_results.append(models[0].predict(X_test))\n",
    "    \n",
    "    for i in range(1, ampNumber):\n",
    "        models[i].fit(np.hstack((X_train, train_results[i - 1])), y_train[:, i * 2: i * 2 + 2])\n",
    "        train_results.append(models[i].predict(np.hstack((X_train, train_results[i - 1]))))\n",
    "        test_results.append(models[i].predict(np.hstack((X_test, test_results[i - 1]))))\n",
    "    \n",
    "    fig   = plt.figure(figsize = (15, 5))\n",
    "    vGain = np.vectorize(invertGainNorm)\n",
    "    vLoss = np.vectorize(invertLossNorm)\n",
    "    \n",
    "    for i in range(ampNumber):\n",
    "        ax = fig.add_subplot(2, 2, i + 1)\n",
    "        \n",
    "        yGain    = vGain(y_test[:, i * 2])\n",
    "        yLoss    = vLoss(y_test[:, i * 2 + 1])\n",
    "        testGain = vGain(test_results[i][:, 0])\n",
    "        testLoss = vLoss(test_results[i][:, 1])\n",
    "        \n",
    "        ax.scatter(yGain, yLoss)\n",
    "        ax.scatter(testGain, testLoss, c = \"m\")\n",
    "        ax.set_title(\"Amplifier {}\".format(i + 1))\n",
    "    \n",
    "    fig.suptitle(\"Test Error\", fontsize = 16)\n",
    "    fig.text(0.5, 0.04, 'Gain', ha='center', va='center', fontsize = 14)\n",
    "    fig.text(0.06, 0.5, 'Loss', ha='center', va='center', rotation='vertical', fontsize = 14)\n",
    "    fig.legend([\"expected\", \"predicted\"])\n",
    "\n",
    "    plt.show()\n",
    "    return y_test, test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotGainError(yTest, predicted):\n",
    "    fig, axis = plt.subplots(figsize = (10, 5))\n",
    "    data      = []\n",
    "    \n",
    "    for i in range(ampNumber):\n",
    "        gainError = []\n",
    "        \n",
    "        yTestAmp     = yTest[:, i * 2]\n",
    "        predictedAmp = predicted[i][:, 0]\n",
    "        \n",
    "        for a, b in zip(predictedAmp, yTestAmp):\n",
    "            gainError.append(math.sqrt(getGainError(a, b))) \n",
    "        \n",
    "        data.append(gainError)\n",
    "        \n",
    "    axis.boxplot(data)\n",
    "    axis.set_title(\"Test Gain Error\", fontsize = 16)\n",
    "    axis.set_xticklabels(np.repeat(strategyArray, 1))\n",
    "    axis.set_ylabel(\"Absolute error (dB)\", fontsize = 14)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLossError(yTest, predicted):\n",
    "    fig, axis = plt.subplots(figsize = (10, 5))\n",
    "    data      = []\n",
    "    \n",
    "    for i in range(ampNumber):\n",
    "        lossError = []\n",
    "        \n",
    "        yTestAmp     = yTest[:, i * 2 + 1]\n",
    "        predictedAmp = predicted[i][:, 1]\n",
    "        \n",
    "        for a, b in zip(predictedAmp, yTestAmp):\n",
    "            lossError.append(math.sqrt(getLossError(a, b))) \n",
    "        \n",
    "        data.append(lossError)\n",
    "        \n",
    "    axis.boxplot(data)\n",
    "    axis.set_title(\"Test Loss Error\", fontsize = 16)\n",
    "    axis.set_xticklabels(np.repeat(strategyArray, 1))\n",
    "    axis.set_ylabel(\"Absolute error (dB)\", fontsize = 14)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLinkTestError(yTest, predicted):\n",
    "    fig, axis = plt.subplots(figsize = (10, 5))\n",
    "    lossData  = [] \n",
    "    gainData  = [] \n",
    "    \n",
    "    yTestGain     = yTest[:, 0]\n",
    "    yTestLoss     = yTest[:, 1]\n",
    "    predictedGain = np.array(predicted[0][:, 0]).flatten()\n",
    "    predictedLoss = np.array(predicted[0][:, 1]).flatten()\n",
    "    \n",
    "    for i in range(1, ampNumber):\n",
    "        yTestGain     = np.hstack((yTestGain, yTest[:, i * 2]))\n",
    "        yTestLoss     = np.hstack((yTestLoss, yTest[:, i * 2 + 1]))\n",
    "        predictedGain = np.hstack((predictedGain, np.array(predicted[i][:, 0]).flatten()))\n",
    "        predictedLoss = np.hstack((predictedLoss, np.array(predicted[i][:, 1]).flatten()))\n",
    "    \n",
    "    for i in range(len(yTestGain)):\n",
    "        lossData.append(getLossError(predictedLoss[i], yTestLoss[i]))\n",
    "        gainData.append(getGainError(predictedGain[i], yTestGain[i]))\n",
    "            \n",
    "    print(\"Loss error mean: {}. Loss error median: {}\".format(math.sqrt(np.mean(lossData)), np.median(lossData)))\n",
    "    print(\"Gain error mean: {}. Gain error median: {}\".format(math.sqrt(np.mean(gainData)), np.median(gainData)))\n",
    "    \n",
    "    axis.boxplot([lossData, gainData])\n",
    "    axis.set_title(\"Link Test Error\", fontsize = 16)\n",
    "    axis.set_xticklabels([\"Gain\", \"Loss\"])\n",
    "    axis.set_ylabel(\"Absolute error (dB)\", fontsize = 14)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gainArray = []\n",
    "lossArray = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'auto', 'leaf_size': 10, 'n_neighbors': 6, 'weights': 'distance'}\n",
      "{'algorithm': 'brute', 'leaf_size': 10, 'n_neighbors': 6, 'weights': 'uniform'}\n",
      "{'algorithm': 'brute', 'leaf_size': 10, 'n_neighbors': 6, 'weights': 'uniform'}\n",
      "{'algorithm': 'auto', 'leaf_size': 20, 'n_neighbors': 6, 'weights': 'uniform'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultiOutputRegressor(estimator=KNeighborsRegressor())"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initModels()\n",
    "\n",
    "#models = initModels()\n",
    "#trainModel(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#yTest, predicted = plotDistribution(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotGainError(yTest, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plotLossError(yTest, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotLinkTestError(yTest, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X, y = loadDataset()\\n\\nplotLearningCurves(0, models[0], X, y[:, 0: 2], 5)\\nprediction = models[0].predict(X)\\n\\nfor i in range(1, ampNumber):\\n    newX = np.hstack((X, prediction))\\n    \\n    plotLearningCurves(i, models[i], X, y[:, i * 2 : i * 2 + 2], 5)\\n    prediction = models[i].predict(newX)'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''X, y = loadDataset()\n",
    "\n",
    "plotLearningCurves(0, models[0], X, y[:, 0: 2], 5)\n",
    "prediction = models[0].predict(X)\n",
    "\n",
    "for i in range(1, ampNumber):\n",
    "    newX = np.hstack((X, prediction))\n",
    "    \n",
    "    plotLearningCurves(i, models[i], X, y[:, i * 2 : i * 2 + 2], 5)\n",
    "    prediction = models[i].predict(newX)'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acopEnv",
   "language": "python",
   "name": "acopenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
