{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "ampNumber   = 2\n",
    "layerArray  = [2, 3, 4, 5, 6]\n",
    "neuronArray = [32, 64, 128, 256, 512, 1024]\n",
    "markers     = [\"o\", \"^\", \"P\", \"s\", \"D\", \"x\"]\n",
    "\n",
    "trainErrors    = []\n",
    "testGainArray  = []\n",
    "testLossArray  = []\n",
    "binaryDataSet  = []\n",
    "\n",
    "originalDataSet = pd.read_csv('../datasets/1_channel_type/dataset-{}.txt'.format(ampNumber), sep = ',',header = None)\n",
    "\n",
    "for line in originalDataSet.values:\n",
    "    myList = [1 if j != 0 else 0 for j in line[:40]]\n",
    "    myList.extend(line[40:])\n",
    "    binaryDataSet.append(myList)\n",
    "\n",
    "binaryDataSet = pd.DataFrame(binaryDataSet)\n",
    "gainScaler    = MinMaxScaler(feature_range = (-1, 1))\n",
    "lossScaler    = MinMaxScaler(feature_range = (-1, 1))\n",
    "\n",
    "gainScalerAux = []\n",
    "lossScalerAux = []\n",
    "    \n",
    "for j in range(0, ampNumber * 2, 2):\n",
    "    gainScalerAux.extend(binaryDataSet.values[:, 40 + j])\n",
    "    lossScalerAux.extend(binaryDataSet.values[:, 40 + j + 1])\n",
    "\n",
    "gainScaler.fit(np.array(gainScalerAux).reshape(-1, 1))\n",
    "lossScaler.fit(np.array(lossScalerAux).reshape(-1, 1))\n",
    "\n",
    "def loadDataset(): \n",
    "    dataSet = binaryDataSet.values[:, :40]\n",
    "    \n",
    "    for i in range(0, ampNumber * 2, 2):\n",
    "        gain    = np.array(binaryDataSet.values[:, 40 + i])\n",
    "        gain    = gainScaler.transform(gain.reshape(-1, 1))\n",
    "        dataSet = np.hstack((dataSet, gain))\n",
    "        \n",
    "        loss    = np.array(binaryDataSet.values[:, 40 + i + 1])\n",
    "        loss    = lossScaler.transform(loss.reshape(-1, 1))\n",
    "        dataSet = np.hstack((dataSet, loss))\n",
    "            \n",
    "    features, result = np.array(dataSet[:, :40]), np.array(dataSet[:, 40:])\n",
    "    return features, result\n",
    "\n",
    "def invertGainNorm(value):\n",
    "    auxArray = np.array([value, 0, 0, 0, 0, 0]).reshape(-1, 1)\n",
    "    return gainScaler.inverse_transform(auxArray)[0][0]\n",
    "\n",
    "def invertLossNorm(value):\n",
    "    auxArray = np.array([value, 0, 0, 0, 0, 0]).reshape(-1, 1)\n",
    "    return lossScaler.inverse_transform(auxArray)[0][0]\n",
    "    \n",
    "def getGainError(value1, value2):\n",
    "    return (invertGainNorm(value1) - invertGainNorm(value2))**2\n",
    "\n",
    "def getLossError(value1, value2):\n",
    "    return (invertLossNorm(value1) - invertLossNorm(value2))**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and validation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def getTrainError(regressor, X, y):\n",
    "    errors = []\n",
    "    \n",
    "    for i in range(30):\n",
    "        history = regressor.fit(X, y, epochs = 50, verbose = False)\n",
    "        errors.append(history.history[\"mse\"])\n",
    "    \n",
    "    return np.mean(errors)\n",
    "\n",
    "def getTestErrors(regressor, X, y, folds = 5):\n",
    "    foldSize       = math.ceil(X.shape[0] / folds)\n",
    "    testGainErrors = []\n",
    "    testLossErrors = []\n",
    "    \n",
    "    for i in range(folds): \n",
    "        sliceBegin = i * foldSize\n",
    "        sliceEnd   = (i + 1) * foldSize\n",
    "        \n",
    "        X_train = np.delete(X, np.s_[sliceBegin: sliceEnd], 0)\n",
    "        y_train = np.delete(y, np.s_[sliceBegin: sliceEnd], 0)\n",
    "        X_test  = X[sliceBegin: sliceEnd]\n",
    "        y_test  = y[sliceBegin: sliceEnd]\n",
    "\n",
    "        regressor.fit(X_train, y_train)\n",
    "        \n",
    "        gainError  = 0\n",
    "        lossError  = 0\n",
    "        prediction = regressor.predict(X_test)\n",
    "        \n",
    "        for predicted, expected in zip(prediction, y_test):\n",
    "            for i in range(0, ampNumber * 2, 2):\n",
    "                gainError += getGainError(predicted[i], expected[i]) \n",
    "                lossError += getLossError(predicted[i + 1], expected[i + 1])\n",
    "                 \n",
    "        testGainErrors.append((gainError / ampNumber) / foldSize)\n",
    "        testLossErrors.append((lossError / ampNumber) / foldSize)\n",
    "        \n",
    "    return np.array(testGainErrors), np.array(testLossErrors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def trainModel(strategy):    \n",
    "    features, result = loadDataset()\n",
    "    trainError       = getTrainError(strategy, features, result)\n",
    "    print(trainError)\n",
    "    \n",
    "    return trainError\n",
    "\n",
    "def testModel(strategy):    \n",
    "    features, result       = loadDataset()\n",
    "    gainErrors, lossErrors = getTestErrors(strategy, features, result)\n",
    "    \n",
    "    print(\"Test errors\")\n",
    "    print(gainErrors, \"=> %0.2f (+/- %0.2f)\" % (np.mean(gainErrors), gainErrors.std() * 2))\n",
    "    print(lossErrors, \"=> %0.2f (+/- %0.2f)\" % (np.mean(lossErrors), lossErrors.std() * 2))\n",
    "    print()\n",
    "    \n",
    "    return np.mean(gainErrors), np.mean(lossErrors)\n",
    "\n",
    "def setModel(layerNumber, neuronNumber):\n",
    "    model = Sequential()\n",
    "    \n",
    "    if layerNumber == 2:\n",
    "        model = keras.Sequential([\n",
    "                    layers.Dense(neuronNumber, activation='relu', input_shape = [40]),\n",
    "                    layers.Dense(neuronNumber, activation='relu'),\n",
    "                    layers.Dense(2 * ampNumber)\n",
    "                ])\n",
    "\n",
    "    if layerNumber == 3:\n",
    "        model = keras.Sequential([\n",
    "                    layers.Dense(neuronNumber, activation='relu', input_shape = [40]),\n",
    "                    layers.Dense(neuronNumber, activation='relu'),\n",
    "                    layers.Dense(neuronNumber, activation='relu'),\n",
    "                    layers.Dense(2 * ampNumber)\n",
    "                ])\n",
    "        \n",
    "    if layerNumber == 4:\n",
    "        model = keras.Sequential([\n",
    "                    layers.Dense(neuronNumber, activation='relu', input_shape = [40]),\n",
    "                    layers.Dense(neuronNumber, activation='relu'),\n",
    "                    layers.Dense(neuronNumber, activation='relu'),\n",
    "                    layers.Dense(neuronNumber, activation='relu'),\n",
    "                    layers.Dense(2 * ampNumber)\n",
    "                ])\n",
    "        \n",
    "    if layerNumber == 5:\n",
    "        model = keras.Sequential([\n",
    "                    layers.Dense(neuronNumber, activation='relu', input_shape = [40]),\n",
    "                    layers.Dense(neuronNumber, activation='relu'),\n",
    "                    layers.Dense(neuronNumber, activation='relu'),\n",
    "                    layers.Dense(neuronNumber, activation='relu'),\n",
    "                    layers.Dense(neuronNumber, activation='relu'),\n",
    "                    layers.Dense(2 * ampNumber)\n",
    "                ])\n",
    "        \n",
    "    if layerNumber == 6:\n",
    "        model = keras.Sequential([\n",
    "                    layers.Dense(neuronNumber, activation='relu', input_shape = [40]),\n",
    "                    layers.Dense(neuronNumber, activation='relu'),\n",
    "                    layers.Dense(neuronNumber, activation='relu'),\n",
    "                    layers.Dense(neuronNumber, activation='relu'),\n",
    "                    layers.Dense(neuronNumber, activation='relu'),\n",
    "                    layers.Dense(neuronNumber, activation='relu'),\n",
    "                    layers.Dense(2 * ampNumber)\n",
    "                ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotError():\n",
    "    fig, axis = plt.subplots(figsize = (10, 5))\n",
    "\n",
    "    for i in range(len(layerArray)):\n",
    "        axis.plot(neuronArray, trainErrors[i])\n",
    "        axis.scatter(neuronArray, trainErrors[i], marker = markers[i])\n",
    "    \n",
    "    axis.set_title(\"Train error for {} amplifiers\".format(ampNumber))\n",
    "    axis.set_xlabel(\"Neuron number\")\n",
    "    axis.set_ylabel(\"MSE (dB)\")\n",
    "    axis.legend([\"{} hidden layers\".format(x) for x in layerArray])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plotLossError():\n",
    "    fig, axis = plt.subplots(figsize = (10, 5))\n",
    "\n",
    "    for i in range(len(layerArray)):\n",
    "        axis.plot(neuronArray, trainLossArray[i])\n",
    "        axis.scatter(neuronArray, trainLossArray[i], marker = markers[i])\n",
    "    \n",
    "    axis.set_title(\"Loss error for {} amplifiers\".format(ampNumber))\n",
    "    axis.set_xlabel(\"Neuron number\")\n",
    "    axis.set_ylabel(\"MAE (dB)\")\n",
    "    axis.legend([\"{} hidden layers\".format(x) for x in layerArray])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 layers\n",
      "0.15339874921242397\n",
      "0.15305077177286147\n",
      "0.1531487553914388\n",
      "0.15309448645512264\n"
     ]
    }
   ],
   "source": [
    "for layerNumber in layerArray:\n",
    "    print(layerNumber, \"layers\")\n",
    "    trainErrors.append([])\n",
    "    \n",
    "    for neurons in neuronArray:\n",
    "        model = setModel(layerNumber, neurons)\n",
    "        model.compile(loss      = 'mse',\n",
    "                      optimizer = \"adam\",\n",
    "                      metrics   = ['mae', 'mse'])\n",
    "\n",
    "        \n",
    "        trainError = trainModel(model)\n",
    "        trainErrors[-1].append(trainError)\n",
    "\n",
    "print(trainErrors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotError()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acopEnv",
   "language": "python",
   "name": "acopenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
