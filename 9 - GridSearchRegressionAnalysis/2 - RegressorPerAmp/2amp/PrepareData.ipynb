{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leandro/.local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from lazypredict.Supervised import LazyRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "path      = os.getcwd()\n",
    "ampNumber = int(os.path.basename(path)[0])\n",
    "\n",
    "originalDataset = pd.read_csv('../../datasets/dataset-{}.txt'.format(ampNumber), sep = ',', header = None)\n",
    "binaryDataset   = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def datasetBalancing(dataset):\n",
    "    newDataset      = []\n",
    "    linesPerChannel = []\n",
    "    currentChannel  = 2\n",
    "\n",
    "    # Finding channel minimum target \n",
    "    count = 0\n",
    "    for line in dataset.values:\n",
    "        channels = np.count_nonzero(line[0: 40], axis=0)\n",
    "\n",
    "        if currentChannel == channels:\n",
    "            count += 1\n",
    "        else:\n",
    "            linesPerChannel.append(count)\n",
    "\n",
    "            currentChannel = channels\n",
    "            count          = 0\n",
    "\n",
    "    linesPerChannel.append(count)   \n",
    "    \n",
    "    print(linesPerChannel)\n",
    "    \n",
    "    guide = np.array(linesPerChannel)\n",
    "    guide = guide[guide != 0]\n",
    "    \n",
    "    showGuides(guide)\n",
    "    \n",
    "    target     = min(guide)\n",
    "    newDataset = cutDown(dataset, guide, target)\n",
    "    \n",
    "    return newDataset\n",
    "\n",
    "def cutDown(dataset, guide, target):\n",
    "    newDataset   = []\n",
    "    currentEntry = 0\n",
    "\n",
    "    for entry in guide:\n",
    "        #print(currentEntry, currentEntry + target)\n",
    "\n",
    "        subset = dataset.values[currentEntry : currentEntry + target]\n",
    "        newDataset.extend(subset)\n",
    "        currentEntry += entry\n",
    "    \n",
    "    return newDataset\n",
    "\n",
    "def showGuides(guide):\n",
    "    channels = [2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30, 40]\n",
    "    \n",
    "    for c, g in zip(channels, guide):\n",
    "        print(\"{} chs: {} entries\".format(c, g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data proccessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200, 179, 219, 199, 209, 219, 1239, 1238, 976, 179, 809, 919, 219]\n",
      "2 chs: 200 entries\n",
      "3 chs: 179 entries\n",
      "4 chs: 219 entries\n",
      "5 chs: 199 entries\n",
      "6 chs: 209 entries\n",
      "7 chs: 219 entries\n",
      "8 chs: 1239 entries\n",
      "9 chs: 1238 entries\n",
      "10 chs: 976 entries\n",
      "15 chs: 179 entries\n",
      "20 chs: 809 entries\n",
      "30 chs: 919 entries\n",
      "40 chs: 219 entries\n"
     ]
    }
   ],
   "source": [
    "balancedDataset = datasetBalancing(originalDataset)\n",
    "\n",
    "for line in balancedDataset:\n",
    "    myList = [1 if j != 0 else 0 for j in line[:40]]\n",
    "    myList.extend(line[40:])\n",
    "    binaryDataset.append(myList)\n",
    "\n",
    "binaryDataset = pd.DataFrame(binaryDataset)\n",
    "\n",
    "def loadDataset(): \n",
    "    dataset = binaryDataset.values[:, :40]\n",
    "    \n",
    "    for i in range(0, ampNumber * 2, 2):\n",
    "        gain    = np.array(binaryDataset.values[:, 40 + i])\n",
    "        gain    = gain.reshape(-1, 1)\n",
    "        dataset = np.hstack((dataset, gain))\n",
    "        \n",
    "        loss    = np.array(binaryDataset.values[:, 40 + i + 1])\n",
    "        loss    = loss.reshape(-1, 1)\n",
    "        dataset = np.hstack((dataset, loss))\n",
    "                \n",
    "    X, y = np.array(dataset[:, :40]), np.array(dataset[:, 40:])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 32/43 [00:08<00:05,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANSACRegressor model failed to execute\n",
      "RANSAC could not find a valid consensus set. All `max_trials` iterations were skipped because each randomly chosen sub-sample failed the passing criteria. See estimator attributes for diagnostics (n_skips*).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 38/43 [00:09<00:01,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StackingRegressor model failed to execute\n",
      "__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:09<00:00,  4.45it/s]\n",
      " 21%|██        | 9/43 [00:00<00:02, 12.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GammaRegressor model failed to execute\n",
      "Some value(s) of y are out of the valid range for family GammaDistribution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 37/43 [00:06<00:00,  6.49it/s]"
     ]
    }
   ],
   "source": [
    "summaryList = []\n",
    "\n",
    "#1 regressor per amplifier\n",
    "X, y = loadDataset()\n",
    "\n",
    "for j in range(0, ampNumber * 2):\n",
    "    reg = LazyRegressor(verbose = 0, ignore_warnings = False)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y[:, j], test_size = 0.3, random_state = 0)\n",
    "    models, summary                  = reg.fit(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    summaryList.append(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalList = []\n",
    "\n",
    "'''\n",
    "if i % 2 ==0 -> it's a gain regressor\n",
    "else         -> it's a loss regressor\n",
    "'''\n",
    "\n",
    "for i in range(0, ampNumber * 2, 2): \n",
    "    myDict = {}\n",
    "    finalList.append(myDict)\n",
    "    \n",
    "    for j in range(min(len(summaryList[i]['RMSE']), len(summaryList[i + 1]['RMSE']))):\n",
    "        if summaryList[i]['RMSE'].index[j] in summaryList[i + 1]['RMSE']: #checking if gain model exists in loss dataframe\n",
    "            \n",
    "            '''\n",
    "            summaryList[i]['RMSE'].index[j] -> j model's name for regressor i \n",
    "            summaryList[i]['RMSE'][j]       -> j model's RMSE for regressor i\n",
    "            summaryList[i + 1]['RMSE'][j]   -> j model's RMSE for regressor i + 1\n",
    "            '''\n",
    "        \n",
    "            finalList[-1][summaryList[i]['RMSE'].index[j]] = [summaryList[i]['RMSE'][j], summaryList[i + 1]['RMSE'][j]]\n",
    "\n",
    "#finalList[i][modelName] -> [gain RMSE, loss RMSE] for modelName of amp #(i + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_gain_loss(item):\n",
    "    return item[1] + item[2]\n",
    "\n",
    "def prepTable(ampIndex):    \n",
    "    rowLabels = [] # Nomes das linhas\n",
    "    colLabels = [] # Nomes das colunas   \n",
    "    values    = [] # Valores das células\n",
    "    sumList   = [] # Soma dos valores\n",
    "    \n",
    "    colLabels = [\"Amp {} Gain\".format(ampIndex + 1), \"Amp {} Loss\".format(ampIndex + 1), \"Avg\"] \n",
    "    \n",
    "    # TODO: Ordenar esta lista de forma decrescente pela soma de ganho e perda (data[i][1] + data[i][2])\n",
    "    data = finalList[ampIndex] \n",
    "    data = dict(sorted(data.items(), key = lambda x : x[1][0] + x[1][1]))\n",
    "    \n",
    "    for key in data:\n",
    "        model = key\n",
    "        gain  = data[key][0]\n",
    "        loss  = data[key][1]\n",
    "        total = gain + loss\n",
    "        \n",
    "        rowLabels.append(model)\n",
    "        values.append([gain, loss, total])    \n",
    "        sumList.append(total)\n",
    "    \n",
    "    return rowLabels, colLabels, values, sumList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols, values, sumList = prepTable(0)\n",
    "commonRegressors = rows\n",
    "\n",
    "for i in range(1, ampNumber): \n",
    "    rows, cols, values, sumList = prepTable(i)\n",
    "    commonRegressors = set.intersection(set(commonRegressors), set(rows))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acopEnv",
   "language": "python",
   "name": "acopenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
